{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import unicodedata\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import psycopg2\n",
    "import yaml\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lista de Problemas\n",
    "\n",
    "Nome repetido\n",
    "Acentuação\n",
    "Nome composto +3\n",
    "Capitalização\n",
    "Tempo computacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'congresso_em_numeros/'\n",
    "deputados = 'deputados.csv'\n",
    "tramitacao = 'tramitacao.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def connect_sqlalchemy():\n",
    "    with open('server_config.yaml', 'r') as f:\n",
    "        server = yaml.load(f)\n",
    "\n",
    "    host = server['host']\n",
    "    database = server['database']\n",
    "    user = server['user']\n",
    "    password = server['password']\n",
    "\n",
    "    from sqlalchemy import create_engine\n",
    "    url = 'postgresql://{}:{}@{}/{}'\n",
    "    url = url.format(user, password, host, database)\n",
    "    return create_engine(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con = connect_sqlalchemy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dados_tramitacao = pd.read_sql_table(table_name='camdep_proposicoes_tramitacao', schema='c_camdep', con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dados_deputado = pd.read_csv(os.path.join(path,deputados), names = ['nome_completo', 'nome', 'id'])\n",
    "#dados_tramitacao = pd.read_csv(os.path.join(path,tramitacao))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removendo NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dados_tramitacao = dados_tramitacao.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Removendo pontuação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_accents(input_str):\n",
    "    if type(input_str) is float:\n",
    "        if math.isnan(input_str):\n",
    "            return \n",
    "\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    return u\"\".join([c for c in nfkd_form if not unicodedata.combining(c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dados_tramitacao[\"despacho\"] = dados_tramitacao[\"despacho\"].apply(lambda x: remove_accents(x))\n",
    "dados_deputado[\"nome_completo\"] = dados_deputado[\"nome_completo\"].apply(lambda x: remove_accents(x))\n",
    "dados_deputado[\"nome\"] = dados_deputado[\"nome\"].apply(lambda x: remove_accents(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deixando tudo em caixa baixa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dados_tramitacao[\"despacho\"] = dados_tramitacao[\"despacho\"].apply(lambda x: x.lower())\n",
    "dados_deputado[\"nome_completo\"] = dados_deputado[\"nome_completo\"].apply(lambda x: x.lower())\n",
    "dados_deputado[\"nome\"] = dados_deputado[\"nome\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dados_deputado = dados_deputado.drop_duplicates(['nome', 'id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modificando as ids que não deviam estar duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = defaultdict(list)\n",
    "for i,item in enumerate(dados_tramitacao.id_tramitacao):\n",
    "    D[item].append(i)\n",
    "D = {k:v for k,v in D.items() if len(v)>1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in D:\n",
    "    \n",
    "    hash_nova = hashlib.sha1(str(i).encode('utf-8')).hexdigest()    \n",
    "    dados_tramitacao.id_tramitacao[D[i][1]:(D[i][1]+1)] = hash_nova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dicionario politicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dicionario_deputados = {}\n",
    "colunas = [\"nome_completo\", \"nome\"]\n",
    "\n",
    "for i in dados_deputado.index:\n",
    "    for j in colunas:\n",
    "        dicionario_deputados[dados_deputado.loc[i, j]] = dados_deputado.id[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indice invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preparando o corpus\n",
    "\n",
    "import unicodedata\n",
    "def remove_accents(input_str):\n",
    "    if type(input_str) is float:\n",
    "        if math.isnan(input_str):\n",
    "            return \n",
    "\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    return u\"\".join([c for c in nfkd_form if not unicodedata.combining(c)])\n",
    "\n",
    "dados_tramitacao[\"despacho\"] = dados_tramitacao[\"despacho\"].apply(lambda x: remove_accents(x))\n",
    "dados_tramitacao['despacho'] = dados_tramitacao['despacho'].apply(lambda texto: [token.lower() for token in WordPunctTokenizer().tokenize(texto)])\n",
    "\n",
    "#pickle.dump(tramitacao, open('congresso_em_numeros/tramitacao.p', 'wb') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def default_to_dict(dic):\n",
    "    for key in dic.keys():\n",
    "        dic[key] = dict(dic[key])\n",
    "    return dict(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "indice = defaultdict(lambda: defaultdict(lambda: []))\n",
    "\n",
    "for i, row in tqdm.tqdm(enumerate(dados_tramitacao.iterrows())):\n",
    "    for j, token in enumerate(row[1]['despacho']):\n",
    "        indice[token][row[0]].append(j)\n",
    "\n",
    "        \n",
    "#pickle.dump(default_to_dict(indice), open('congresso_em_numeros/indice.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontrar nome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def busca_frase(frase, indice):\n",
    "        \n",
    "    lista_frase = frase.split()\n",
    "    \n",
    "    #documeno conterá todos no inicio, para auxiliar na interseção\n",
    "    documento = set(range(0, 10000000))\n",
    "    \n",
    "    #Objeto para receber as informações no final\n",
    "    lista_documentos = {}\n",
    "    \n",
    "    #Vendo todos documentos que todas as palavras aparecerem\n",
    "    for i in lista_frase:\n",
    "        documento = documento.intersection(indice[i])\n",
    "    \n",
    "    #Passando pelos documentos\n",
    "    for j in documento:\n",
    "        \n",
    "        id_despacho = dados_tramitacao.id_tramitacao[j]\n",
    "        #Lista posição irá receber todas as posições que as palavras aparecem por documento\n",
    "        lista_posicao = []\n",
    "        #Passando por cada frase no loop de cada documento\n",
    "        for i in lista_frase:\n",
    "            \n",
    "            lista_posicao.append(np.array(list(indice[i][j])))\n",
    "        \n",
    "        #Variável para auxiliar no for e podemos ter uma variável para receber as interseções\n",
    "        aux_lista_posicao = lista_posicao[0]\n",
    "        \n",
    "        for h in range(1, len(lista_posicao)):\n",
    "            \n",
    "            #Somo 1 na lista auxiliar, porque pela ordenação a proxíma palavra tem que estar na posição seguinte \n",
    "            aux_lista_posicao = np.intersect1d(aux_lista_posicao +1, lista_posicao[h])                        \n",
    "            \n",
    "        #para não salvar os documentos vazios\n",
    "        if len(aux_lista_posicao) > 0:\n",
    "            lista_documentos[id_despacho] = (aux_lista_posicao - len(lista_posicao))\n",
    "        \n",
    "    return lista_documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def todos_deputados(dic, indice):\n",
    "    \n",
    "    dic_final = defaultdict(lambda: list())\n",
    "    \n",
    "    for parlamentar in tqdm.tqdm(dic.keys(), total = len(dic.keys())):\n",
    "        \n",
    "        posicao = busca_frase(parlamentar, indice)\n",
    "        \n",
    "        if len(posicao) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            for pos in posicao.keys():\n",
    "                dic_final[dic[parlamentar]].append(pos)\n",
    "    \n",
    "    return dic_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_final = todos_deputados(dicionario_deputados, indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lista_final_2 = dict(lista_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileObject = open(\"congresso_em_numeros/lista_final\",'wb') \n",
    "pickle.dump(lista_final_2 ,fileObject, protocol = 4)  \n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando a nossa lista de despachos e tokenizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario_deputados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_final[74173]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisis of voting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "votacao_deputado.groupby(['voto']).count()['ano']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that those are the types of votes on the database\n",
    "\n",
    "- 'Sim' and 'Não' are Yes or No votes\n",
    "\n",
    "- 'Obstrução' means Obstruction\n",
    "\n",
    "- 'Abstenção' means Abstention\n",
    "\n",
    "- 'Art. 17' means Article 17 which refers to prohibts the President of the House from voting\n",
    "\n",
    "- 'Branco' means Blank vote, but it just appeared once, so it is certantly a mistake.\n",
    "\n",
    "- '-' corresponds to the absence of the congressman\n",
    "\n",
    "Since I am interested on congressman with the same behaviour that will form edges on the graph, it seems reasonable to delete the following vote types: 'Art. 17', 'Branco'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming '-' to 'Abstenção'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "votacao_deputado.voto[votacao_deputado.voto == '-'] = 'Abstenção'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "votacao_deputado = votacao_deputado[(votacao_deputado['voto'] != 'Art. 17') &\n",
    "                 (votacao_deputado['voto'] != 'Branco')]\n",
    "votacao_deputado.groupby(['voto']).count()['ano']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "votacao_deputado = votacao_deputado.drop(['codproposicao', 'tipo', 'numero', 'ano', 'codsessao',\n",
    "       'idecadastro', 'partido', 'uf'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "votacao_group = list(votacao_deputado.groupby(['votacao_id', 'voto']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_final = votacao_group[0][1]\n",
    "base_final = base_final.iloc[0:1]\n",
    "base_final['edge'] = 'apagar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(votacao_group)):\n",
    "    aux = votacao_group[i][1]\n",
    "    \n",
    "    for j in range(0, len(aux)):\n",
    "        aux['edge'] = aux.nome[aux.index[j]]\n",
    "        aux.edge[aux.index[j]] = 'apagar'\n",
    "        \n",
    "        base_final = base_final.append(aux)\n",
    "        aux = aux.drop('edge', axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
